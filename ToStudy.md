# Optimization algorithms
    - Why is the best mini-batch size usually not 1 and not m, but instead something in-between?
    - Adam
    - Momentum
    
    출처 http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html
    
# Bird recognition in the city of Peacetopia
    - What's difference human-level perormance and Bayes error
    - What happens after decrease the regularization
    - You have more false negatives than other's algorithm, What will you do?
    